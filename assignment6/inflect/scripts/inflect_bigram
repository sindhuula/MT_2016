#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Outputs a fully inflected version of a lemmatized test set (provided on STDIN). 
If training data is provided, it will use a unigram model to select the form.

usage: cat LEMMA_FILE | python inflect
       [-t TRAINING_PREFIX] [-l LEMMA_SUFFIX] [-w WORD_SUFFIX]
"""

import argparse
import codecs
import sys
import os
from collections import defaultdict
from itertools import izip

PARSER = argparse.ArgumentParser(description="Inflect a lemmatized corpus")
PARSER.add_argument("-t", type=str, default="data/train", help="training data prefix")
PARSER.add_argument("-l", type=str, default="lemma", help="lemma file suffix")
PARSER.add_argument("-w", type=str, default="form", help="word file suffix")
args = PARSER.parse_args()

# Python sucks at UTF-8
sys.stdout = codecs.getwriter('utf-8')(sys.stdout) 
sys.stdin = codecs.getreader('utf-8')(sys.stdin) 

def inflections(lemma1,lemma2):
    if BI_LEMMAS.has_key((lemma1,lemma2)):
        return sorted(BI_LEMMAS[(lemma1,lemma2)].keys(), lambda x,y: cmp(BI_LEMMAS[(lemma1,lemma2)][y], BI_LEMMAS[(lemma1,lemma2)][x]))
    return [(lemma1,lemma2)]
def best_inflection(lemma1,lemma2):
    return inflections(lemma1,lemma2)[0]
if __name__ == '__main__':

    # Build a simple unigram model on the training data
    LEMMAS = defaultdict(defaultdict)
    BI_LEMMAS = defaultdict(defaultdict)
    if args.t:
        def combine(a, b): return '%s.%s' % (a, b)
        def utf8read(file): return codecs.open(file, 'r', 'utf-8')
        # Build the LEMMAS hash, a two-level dictionary mapping lemmas to inflections to counts
        for words, lemmas in izip(utf8read(combine(args.t, args.w)), utf8read(combine(args.t, args.l))):
            #for word1, lemma in izip(words.rstrip().lower().split(), lemmas.rstrip().lower().split()):
             word_dict = words.rstrip().lower().split()
             lemma_dict = lemmas.rstrip().lower().split()
             for i in range (0,len(word_dict)-1):
                 word1 = word_dict[i]
                 word2 = word_dict[i+1]
                 lemma1 = lemma_dict[i]
                 lemma2 = lemma_dict[i+1]
             #    LEMMAS[lemma1][word1] = LEMMAS[lemma1].get(word1,0) + 1
              #   LEMMAS[lemma2][word2] = LEMMAS[lemma2].get(word2,0) + 1
                 BI_LEMMAS[(lemma1,lemma2)][(word1,word2)] = BI_LEMMAS[(lemma1,lemma2)].get((word1,word2),0) + 1
     #  print BI_LEMMAS
    # Choose the most common inflection for each word and output them as a sentence
    for line in sys.stdin:
        result = ""
        words = line.rstrip().lower().split()
        for i in range (0,len(words)-1):
                     word1 = words[i]
                     word2 = words[i+1]
                     (res_word1,res_word2) = best_inflection(word1,word2)
                     if (i==0):
                         result = res_word1
                     result = result+' '+res_word2
        print result
