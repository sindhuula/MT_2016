#!/usr/bin/env python
from __future__ import division 
import argparse # optparse is deprecated
from itertools import islice # slicing for iterators
from nltk.corpus import wordnet
import sys  

reload(sys)  
sys.setdefaultencoding('utf8')

def findSyn(sentence):
    synlist = []
    for word in sentence:
        for synset in wordnet.synsets(word):
            for syn in synset.lemma_names():
                if syn not in synlist:
                    synlist.append(syn)
        if word not in synlist:
            synlist.append(word)
    return synlist
def word_matches(h, ref):
    return sum(1 for w in h if w in ref)
 
def main():
    parser = argparse.ArgumentParser(description='Evaluate translation hypotheses.')
    parser.add_argument('-i', '--input', default='data/hyp1-hyp2-ref',
            help='input file (default data/hyp1-hyp2-ref)')
    parser.add_argument('-n', '--num_sentences', default=None, type=int,
            help='Number of hypothesis pairs to evaluate')
    # note that if x == [1, 2, 3], then x[:None] == x[:] == x (copy); no need for sys.maxint
    opts = parser.parse_args()
    n = 0
    # we create a generator and avoid loading all sentences into a list
    def sentences():
        with open(opts.input) as f:
            for pair in f:
                yield [sentence.strip().split() for sentence in pair.split(' ||| ')]
 
    a = 0.1
    for h1, h2, ref in islice(sentences(), opts.num_sentences):
        #n = n + 1
        #if n%500 == 0:
        #    print n
        rset = set(ref)
        h1_match = meteor(h1,rset,a) 
        h2_match = meteor(h2,rset,a)
        result = (1 if h1_match > h2_match else # \begin{cases}
                (0 if h1_match == h2_match
                    else -1)) # \end{cases}
        with open('result_wordnet', 'a') as f:
            f.write("%s\n" % str(result))
            
def meteor(h,e,a):
    precision,recall = findPrecisionRecall(h,e)
    try:
        l = (precision*recall) / (((1-a)*recall) + a*precision)
    except ZeroDivisionError:
        l = 0
    return (l)

def findPrecisionRecall(h,e):
    countcommon = 0
    sizeh = len(h)
    sizee = len(e)
    synonyms = findSyn(e)
    countcommon = word_matches(h,synonyms)
    recall = countcommon/sizee
    precision = countcommon/sizeh
    return (precision,recall)
# convention to allow import of this file as a module
if __name__ == '__main__':
    main()
